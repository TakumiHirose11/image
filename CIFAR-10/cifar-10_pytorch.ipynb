{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Don't work..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "root = \"./data\"\n",
    "\n",
    "transform_train = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5),(0.5))]\n",
    ")\n",
    "\n",
    "transform_val = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5),(0.5))]\n",
    ")\n",
    "\n",
    "f_mnist_train = datasets.CIFAR10(\n",
    "    root=root,\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform_train,\n",
    ")\n",
    "f_mnist_test = datasets.CIFAR10(\n",
    "    root=root,\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform_val\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(f_mnist_train, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(f_mnist_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for (x,t) in train_dataloader:\n",
    "    print(x.shape)\n",
    "    print(t.shape)\n",
    "    break\n",
    "\n",
    "for (x,t) in test_dataloader:\n",
    "    print(x.shape)\n",
    "    print(t.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \"\"\"(batch_size, 3, 32, 32) -> (batch_size,  32, 32)\"\"\"\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3,\n",
    "            out_channels=32,\n",
    "            kernel_size=3,\n",
    "            padding=True,\n",
    "            padding_mode=\"zeros\"\n",
    "            )\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=32,\n",
    "            out_channels=32,\n",
    "            kernel_size=3, \n",
    "            padding=True, \n",
    "            padding_mode=\"zeros\")\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.dropout1 = nn.Dropout2d(0.5)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=32, \n",
    "            out_channels=64, \n",
    "            kernel_size=3, \n",
    "            padding=True, \n",
    "            padding_mode=\"zeros\")\n",
    "\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=64, \n",
    "            out_channels=64, \n",
    "            kernel_size=3, \n",
    "            padding=True, \n",
    "            padding_mode=\"zeros\")\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "\n",
    "        self.fc1 = nn.Linear(64*8*8, 512)\n",
    "        \n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(F.relu(self.conv2(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool2(F.relu(self.conv4(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = x.view(-1, 64*8*8) #Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device=device)\n",
    "model\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x, t):\n",
    "    model.train()\n",
    "    preds = model(x)\n",
    "    loss = criterion(preds, t)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backword() #process of backword\n",
    "    optimizer.step()\n",
    "    return loss, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(x, t):\n",
    "    model.eval()\n",
    "    preds = model(x)\n",
    "    loss = criterion(preds, t)\n",
    "    return loss, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "conv2d() received an invalid combination of arguments - got (Tensor, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (Tensor, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (Tensor, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:32\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m/Users/hirosetakumi/development/image/CIFAR-10/cifar-10_pytorch.ipynb Cell 5'\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(x, t)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hirosetakumi/development/image/CIFAR-10/cifar-10_pytorch.ipynb#ch0000005?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_step\u001b[39m(x, t):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hirosetakumi/development/image/CIFAR-10/cifar-10_pytorch.ipynb#ch0000005?line=1'>2</a>\u001b[0m     model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hirosetakumi/development/image/CIFAR-10/cifar-10_pytorch.ipynb#ch0000005?line=2'>3</a>\u001b[0m     preds \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hirosetakumi/development/image/CIFAR-10/cifar-10_pytorch.ipynb#ch0000005?line=3'>4</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(preds, t)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hirosetakumi/development/image/CIFAR-10/cifar-10_pytorch.ipynb#ch0000005?line=4'>5</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniforge3/envs/image/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/hirosetakumi/development/image/CIFAR-10/cifar-10_pytorch.ipynb Cell 2'\u001b[0m in \u001b[0;36mCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hirosetakumi/development/image/CIFAR-10/cifar-10_pytorch.ipynb#ch0000002?line=50'>51</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hirosetakumi/development/image/CIFAR-10/cifar-10_pytorch.ipynb#ch0000002?line=51'>52</a>\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hirosetakumi/development/image/CIFAR-10/cifar-10_pytorch.ipynb#ch0000002?line=52'>53</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool1(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hirosetakumi/development/image/CIFAR-10/cifar-10_pytorch.ipynb#ch0000002?line=53'>54</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/miniforge3/envs/image/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/image/lib/python3.8/site-packages/torch/nn/modules/conv.py:447\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/torch/nn/modules/conv.py?line=445'>446</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/torch/nn/modules/conv.py?line=446'>447</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/miniforge3/envs/image/lib/python3.8/site-packages/torch/nn/modules/conv.py:443\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/torch/nn/modules/conv.py?line=438'>439</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/torch/nn/modules/conv.py?line=439'>440</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/torch/nn/modules/conv.py?line=440'>441</a>\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/torch/nn/modules/conv.py?line=441'>442</a>\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/torch/nn/modules/conv.py?line=442'>443</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/torch/nn/modules/conv.py?line=443'>444</a>\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mTypeError\u001b[0m: conv2d() received an invalid combination of arguments - got (Tensor, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (Tensor, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (Tensor, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "7.モデルを使用して学習する\n",
    "'''\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# エポック数\n",
    "epochs = 120\n",
    "# 損失と精度の履歴を保存するためのdictオブジェクト\n",
    "history = {'loss':[],'accuracy':[], 'test_loss':[], 'test_accuracy':[]}\n",
    "\n",
    "# 収束が停滞したら学習率を減衰するスケジューラー\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,   # オプティマイザーを指定\n",
    "    mode='max',  # 監視対象は最大値\n",
    "    factor=0.5,  # 学習率を減衰する割合\n",
    "    patience=10, # 監視対象のエポック数\n",
    "    min_lr=0.0001, # 最小学習率\n",
    "    verbose=True # 学習率を減衰した場合に通知する\n",
    "    )\n",
    "\n",
    "# 学習を行う\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0. # 訓練1エポックあたりの損失を保持する変数\n",
    "    train_acc = 0.  # 訓練1エポックごとの精度を保持する変数\n",
    "    test_loss = 0.  # 評価1エポックごとの損失を保持する変数\n",
    "    test_acc = 0.   # 評価1エポックごとの精度を保持する変数\n",
    "\n",
    "    # 1ステップにおける訓練用ミニバッチを使用した学習\n",
    "    for (x, t) in train_dataloader:\n",
    "        # torch.Tensorオブジェクトにデバイスを割り当てる\n",
    "        x, t = x.to(device), t.to(device)\n",
    "        loss, preds = train_step(x, t) # 損失と予測値を取得\n",
    "        train_loss += loss.item()      # ステップごとの損失を加算\n",
    "        train_acc += accuracy_score(\n",
    "            t.tolist(),\n",
    "            preds.argmax(dim=-1).tolist()\n",
    "        )                              # ステップごとの精度を加算\n",
    "\n",
    "    # 1ステップにおけるテストデータのミニバッチを使用した評価\n",
    "    for (x, t) in test_dataloader:\n",
    "        # torch.Tensorオブジェクトにデバイスを割り当てる\n",
    "        x, t = x.to(device), t.to(device)\n",
    "        loss, preds = test_step(x, t) # 損失と予測値を取得\n",
    "        test_loss += loss.item()       # ステップごとの損失を加算\n",
    "        test_acc += accuracy_score(\n",
    "            t.tolist(),\n",
    "            preds.argmax(dim=-1).tolist()\n",
    "        )                              # ステップごとの精度を加算\n",
    "\n",
    "    # 訓練時の損失の平均値を取得\n",
    "    avg_train_loss = train_loss / len(train_dataloader)\n",
    "    # 訓練時の精度の平均値を取得\n",
    "    avg_train_acc = train_acc / len(train_dataloader)\n",
    "    # 検証時の損失の平均値を取得\n",
    "    avg_test_loss = test_loss / len(test_dataloader)\n",
    "    # 検証時の精度の平均値を取得\n",
    "    avg_test_acc = test_acc / len(test_dataloader)\n",
    "\n",
    "    # 訓練データの履歴を保存する\n",
    "    history['loss'].append(avg_train_loss)\n",
    "    history['accuracy'].append(avg_train_acc)\n",
    "    # テストデータの履歴を保存する\n",
    "    history['test_loss'].append(avg_test_loss)\n",
    "    history['test_accuracy'].append(avg_test_acc)\n",
    "\n",
    "    # 1エポックごとに結果を出力\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(\n",
    "            'epoch({}) train_loss: {:.4} train_acc: {:.4} val_loss: {:.4} val_acc: {:.4}'.format(\n",
    "                epoch+1,\n",
    "                avg_train_loss, # 訓練データの損失を出力\n",
    "                avg_train_acc,  # 訓練データの精度を出力\n",
    "                avg_test_loss,  # テストデータの損失を出力\n",
    "                avg_test_acc    # テストデータの精度を出力\n",
    "    ))\n",
    "    # スケジューラー、テストデータの精度を監視する\n",
    "    scheduler.step(avg_test_acc)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ebeb28e6b13eca9129251e1a57a607330dbc2c0e4d49cedd0aa8c47b6d160812"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('image')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
