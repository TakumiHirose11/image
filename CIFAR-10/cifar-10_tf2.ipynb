{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def prepare_data():\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    x_train, x_test = x_train.astype('float32'), x_test.astype('float32')\n",
    "    y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class CNN(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        weight_decay = 1e-4\n",
    "        self.std1 = tf.keras.layers.BatchNormalization()\n",
    "        self.std2 = tf.keras.layers.BatchNormalization()\n",
    "        self.std3 = tf.keras.layers.BatchNormalization()\n",
    "        self.std4 = tf.keras.layers.BatchNormalization()\n",
    "        self.std5 = tf.keras.layers.BatchNormalization()\n",
    "        self.std6 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv2D_1 = tf.keras.layers.Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=(3,3),\n",
    "            padding=\"same\",\n",
    "            input_shape=x_train.shape[1:],\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(weight_decay),\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.conv2D_2 = tf.keras.layers.Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=(3,3),\n",
    "            padding=\"same\",\n",
    "            input_shape=x_train[0].shape,\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(weight_decay),\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2,2))\n",
    "        self.dropout1=tf.keras.layers.Dropout(0.2)\n",
    "        self.conv2D_3 = tf.keras.layers.Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=(3,3),\n",
    "            padding=\"same\",\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(weight_decay),\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.conv2D_4 = tf.keras.layers.Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=(3,3),\n",
    "            padding=\"same\",\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(weight_decay),\n",
    "            activation=\"relu\"\n",
    "        )\n",
    "        self.pool2 = tf.keras.layers.MaxPooling2D(\n",
    "            pool_size=(2,2),\n",
    "        )\n",
    "        self.dropout2 = tf.keras.layers.Dropout(0.3)\n",
    "        self.conv2D_5 = tf.keras.layers.Conv2D(\n",
    "            filters=128,\n",
    "            kernel_size=(3,3),\n",
    "            padding=\"same\",\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(weight_decay),\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.conv2D_6 = tf.keras.layers.Conv2D(\n",
    "            filters=128,\n",
    "            kernel_size=(3,3),\n",
    "            padding=\"same\",\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(weight_decay),\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.pool3 = tf.keras.layers.MaxPooling2D(\n",
    "            pool_size=(2,2)\n",
    "        )\n",
    "        self.dropout3 = tf.keras.layers.Dropout(0.4)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc1 = tf.keras.layers.Dense(\n",
    "            128,\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.dropout4 = tf.keras.layers.Dropout(0.4)\n",
    "        self.fc2 = tf.keras.layers.Dense(\n",
    "            10,\n",
    "            activation=\"softmax\",\n",
    "        )\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x, training=None):\n",
    "        x = self.std1(self.conv2D_1(x))\n",
    "        x = self.pool1(self.std2(self.conv2D_2(x)))\n",
    "        if training:\n",
    "            x = self.dropout1(x)\n",
    "        x = self.std3(self.conv2D_3(x))\n",
    "        x = self.pool2(self.std4(self.conv2D_4(x)))\n",
    "        if training:\n",
    "            x = self.dropout2(x)\n",
    "        x = self.std5(self.conv2D_5(x))\n",
    "        x = self.pool3(self.std6(self.conv2D_6(x)))\n",
    "        if training:\n",
    "            x = self.dropout3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        if training:\n",
    "            x = self.dropout4(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "set error function and optimizer\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "update the parameter\n",
    "\"\"\"\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean()\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, t):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = model(x, training=True)\n",
    "        tmp_loss = loss_fn(t, outputs)\n",
    "\n",
    "    grads = tape.gradient(\n",
    "        tmp_loss,\n",
    "        model.trainable_variables\n",
    "    )\n",
    "    optimizer.apply_gradients(\n",
    "        zip(grads, model.trainable_variables)\n",
    "    )\n",
    "    train_loss(tmp_loss)\n",
    "    train_accuracy(t, outputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = tf.keras.metrics.Mean()\n",
    "val_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "@tf.function\n",
    "def valid_step(val_x, val_y):\n",
    "    pred = model(val_x, training=False)\n",
    "    tmp_loss = loss_fn(val_y, pred)\n",
    "    val_loss(tmp_loss)\n",
    "    val_accuracy(val_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "x_train, x_test, y_train, y_test = prepare_data()\n",
    "\n",
    "epochs = 120\n",
    "batch_size = 64\n",
    "train_steps = x_train.shape[0] // batch_size\n",
    "val_steps = x_test.shape[0] // batch_size\n",
    "\n",
    "model = CNN()\n",
    "history = {'loss':[],'accuracy':[], 'val_loss':[], 'val_accuracy':[]}\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    ")\n",
    "\n",
    "\"\"\"normarize the data\"\"\"\n",
    "train_datagen.fit(x_train)\n",
    "test_datagen.fit(x_test)\n",
    "\n",
    "\"apply batch to generator\"\n",
    "train_generator = train_datagen.flow(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow(\n",
    "    x_test,\n",
    "    y_test,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    step_counter = 0\n",
    "    for x_batch, t_batch in train_generator:\n",
    "        train_step(x_batch, t_batch)\n",
    "        step_counter += 1\n",
    "        if step_counter >= train_steps:\n",
    "            break\n",
    "    \n",
    "    v_step_counter = 0\n",
    "    for x_val_batch, t_val_batch in validation_generator:\n",
    "        valid_step(x_val_batch, t_val_batch)\n",
    "        v_step_counter += 1\n",
    "        if v_step_counter >= val_steps:\n",
    "            break\n",
    "\n",
    "    \n",
    "    avg_train_loss = train_loss.result()    # 訓練時の平均損失値を取得\n",
    "    avg_train_acc = train_accuracy.result() # 訓練時の平均正解率を取得\n",
    "    avg_val_loss = val_loss.result()     # 検証時の平均損失値を取得\n",
    "    avg_val_acc = val_accuracy.result()  # 検証時の平均正解率を取得\n",
    "\n",
    "    # 損失の履歴を保存する\n",
    "    history['loss'].append(avg_train_loss)\n",
    "    history['val_loss'].append(avg_val_loss)\n",
    "    # 精度の履歴を保存する\n",
    "    history['accuracy'].append(avg_train_acc)\n",
    "    history['val_accuracy'].append(avg_val_acc)\n",
    "\n",
    "    # 1エポックごとに結果を出力\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(\n",
    "            'epoch({}) train_loss: {:.4} train_acc: {:.4} val_loss: {:.4} val_acc: {:.4}'.format(\n",
    "                epoch+1,\n",
    "                avg_train_loss, # 現在の損失を出力\n",
    "                avg_train_acc,  # 現在の精度を出力\n",
    "                avg_val_loss,   # 現在の損失を出力\n",
    "                avg_val_acc     # 現在の精度を出力\n",
    "    ))\n",
    "\n",
    "# モデルの概要を出力\n",
    "model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ebeb28e6b13eca9129251e1a57a607330dbc2c0e4d49cedd0aa8c47b6d160812"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('image')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
