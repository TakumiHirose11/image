{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def prepare_data():\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    x_train, x_test = x_train.astype('float32'), x_test.astype('float32')\n",
    "    y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class CNN(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        weight_decay = 1e-4\n",
    "        self.std1 = tf.keras.layers.BatchNormalization()\n",
    "        self.std2 = tf.keras.layers.BatchNormalization()\n",
    "        self.std3 = tf.keras.layers.BatchNormalization()\n",
    "        self.std4 = tf.keras.layers.BatchNormalization()\n",
    "        self.std5 = tf.keras.layers.BatchNormalization()\n",
    "        self.std6 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv2D_1 = tf.keras.layers.Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=(3,3),\n",
    "            padding=\"same\",\n",
    "            input_shape=x_train.shape[1:],\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(weight_decay),\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.conv2D_2 = tf.keras.layers.Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=(3,3),\n",
    "            padding=\"same\",\n",
    "            input_shape=x_train[0].shape,\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(weight_decay),\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2,2))\n",
    "        self.dropout1=tf.keras.layers.Dropout(0.2)\n",
    "        self.conv2D_3 = tf.keras.layers.Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=(3,3),\n",
    "            padding=\"same\",\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(weight_decay),\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.conv2D_4 = tf.keras.layers.Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=(3,3),\n",
    "            padding=\"same\",\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(weight_decay),\n",
    "            activation=\"relu\"\n",
    "        )\n",
    "        self.pool2 = tf.keras.layers.MaxPooling2D(\n",
    "            pool_size=(2,2),\n",
    "        )\n",
    "        self.dropout2 = tf.keras.layers.Dropout(0.3)\n",
    "        self.conv2D_5 = tf.keras.layers.Conv2D(\n",
    "            filters=128,\n",
    "            kernel_size=(3,3),\n",
    "            padding=\"same\",\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(weight_decay),\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.conv2D_6 = tf.keras.layers.Conv2D(\n",
    "            filters=128,\n",
    "            kernel_size=(3,3),\n",
    "            padding=\"same\",\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(weight_decay),\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.pool3 = tf.keras.layers.MaxPooling2D(\n",
    "            pool_size=(2,2)\n",
    "        )\n",
    "        self.dropout3 = tf.keras.layers.Dropout(0.4)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc1 = tf.keras.layers.Dense(\n",
    "            128,\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.dropout4 = tf.keras.layers.Dropout(0.4)\n",
    "        self.fc2 = tf.keras.layers.Dense(\n",
    "            10,\n",
    "            activation=\"softmax\",\n",
    "        )\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x, training=None):\n",
    "        x = self.std1(self.conv2D_1(x))\n",
    "        x = self.pool1(self.std2(self.conv2D_2(x)))\n",
    "        if training:\n",
    "            x = self.dropout1(x)\n",
    "        x = self.std3(self.conv2D_3(x))\n",
    "        x = self.pool2(self.std4(self.conv2D_4(x)))\n",
    "        if training:\n",
    "            x = self.dropout2(x)\n",
    "        x = self.std5(self.conv2D_5(x))\n",
    "        x = self.pool3(self.std6(self.conv2D_6(x)))\n",
    "        if training:\n",
    "            x = self.dropout3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        if training:\n",
    "            x = self.dropout4(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "set error function and optimizer\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "update the parameter\n",
    "\"\"\"\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean()\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, t):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = model(x, training=True)\n",
    "        tmp_loss = loss_fn(t, outputs)\n",
    "\n",
    "    grads = tape.gradient(\n",
    "        tmp_loss,\n",
    "        model.trainable_variables\n",
    "    )\n",
    "    optimizer.apply_gradients(\n",
    "        zip(grads, model.trainable_variables)\n",
    "    )\n",
    "    train_loss(tmp_loss)\n",
    "    train_accuracy(t, outputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = tf.keras.metrics.Mean()\n",
    "val_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "@tf.function\n",
    "def valid_step(val_x, val_y):\n",
    "    pred = model(val_x, training=False)\n",
    "    tmp_loss = loss_fn(val_y, pred)\n",
    "    val_loss(tmp_loss)\n",
    "    val_accuracy(val_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(1) train_loss: 0.1921 train_acc: 0.3662 val_loss: 0.3187 val_acc: 0.1028\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/hirosetakumi/development/image/CIFAR-10/cifar-10_tf2.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hirosetakumi/development/image/CIFAR-10/cifar-10_tf2.ipynb#ch0000006?line=45'>46</a>\u001b[0m step_counter \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hirosetakumi/development/image/CIFAR-10/cifar-10_tf2.ipynb#ch0000006?line=46'>47</a>\u001b[0m \u001b[39mfor\u001b[39;00m x_batch, t_batch \u001b[39min\u001b[39;00m train_generator:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hirosetakumi/development/image/CIFAR-10/cifar-10_tf2.ipynb#ch0000006?line=47'>48</a>\u001b[0m     train_step(x_batch, t_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hirosetakumi/development/image/CIFAR-10/cifar-10_tf2.ipynb#ch0000006?line=48'>49</a>\u001b[0m     step_counter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hirosetakumi/development/image/CIFAR-10/cifar-10_tf2.ipynb#ch0000006?line=49'>50</a>\u001b[0m     \u001b[39mif\u001b[39;00m step_counter \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m train_steps:\n",
      "File \u001b[0;32m~/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=825'>826</a>\u001b[0m tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=826'>827</a>\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name) \u001b[39mas\u001b[39;00m tm:\n\u001b[0;32m--> <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=827'>828</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=828'>829</a>\u001b[0m   compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experimental_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=829'>830</a>\u001b[0m   new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m~/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:855\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=851'>852</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=852'>853</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=853'>854</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=854'>855</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=855'>856</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=856'>857</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=857'>858</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=858'>859</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2942\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=2938'>2939</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=2939'>2940</a>\u001b[0m   (graph_function,\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=2940'>2941</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=2941'>2942</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=2942'>2943</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1913'>1914</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1914'>1915</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1915'>1916</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1916'>1917</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1917'>1918</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1918'>1919</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1919'>1920</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1920'>1921</a>\u001b[0m     args,\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1921'>1922</a>\u001b[0m     possible_gradient_type,\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1922'>1923</a>\u001b[0m     executing_eagerly)\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1923'>1924</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py:555\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=552'>553</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=553'>554</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=554'>555</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=555'>556</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=556'>557</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=557'>558</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=558'>559</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=559'>560</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=560'>561</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=561'>562</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=562'>563</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=563'>564</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=566'>567</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=567'>568</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=57'>58</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=58'>59</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=59'>60</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=60'>61</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=61'>62</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "x_train, x_test, y_train, y_test = prepare_data()\n",
    "\n",
    "epochs = 120\n",
    "batch_size = 64\n",
    "train_steps = x_train.shape[0] // batch_size\n",
    "val_steps = x_test.shape[0] // batch_size\n",
    "\n",
    "model = CNN()\n",
    "history = {'loss':[],'accuracy':[], 'val_loss':[], 'val_accuracy':[]}\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    ")\n",
    "\n",
    "\"\"\"normarize the data\"\"\"\n",
    "train_datagen.fit(x_train)\n",
    "test_datagen.fit(x_test)\n",
    "\n",
    "\"apply batch to generator\"\n",
    "train_generator = train_datagen.flow(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow(\n",
    "    x_test,\n",
    "    y_test,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    step_counter = 0\n",
    "    for x_batch, t_batch in train_generator:\n",
    "        train_step(x_batch, t_batch)\n",
    "        step_counter += 1\n",
    "        if step_counter >= train_steps:\n",
    "            break\n",
    "    \n",
    "    v_step_counter = 0\n",
    "    for x_val_batch, t_val_batch in validation_generator:\n",
    "        valid_step(x_val_batch, t_val_batch)\n",
    "        v_step_counter += 1\n",
    "        if v_step_counter >= val_steps:\n",
    "            break\n",
    "\n",
    "    \n",
    "    avg_train_loss = train_loss.result()    # 訓練時の平均損失値を取得\n",
    "    avg_train_acc = train_accuracy.result() # 訓練時の平均正解率を取得\n",
    "    avg_val_loss = val_loss.result()     # 検証時の平均損失値を取得\n",
    "    avg_val_acc = val_accuracy.result()  # 検証時の平均正解率を取得\n",
    "\n",
    "    # 損失の履歴を保存する\n",
    "    history['loss'].append(avg_train_loss)\n",
    "    history['val_loss'].append(avg_val_loss)\n",
    "    # 精度の履歴を保存する\n",
    "    history['accuracy'].append(avg_train_acc)\n",
    "    history['val_accuracy'].append(avg_val_acc)\n",
    "\n",
    "    # 1エポックごとに結果を出力\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(\n",
    "            'epoch({}) train_loss: {:.4} train_acc: {:.4} val_loss: {:.4} val_acc: {:.4}'.format(\n",
    "                epoch+1,\n",
    "                avg_train_loss, # 現在の損失を出力\n",
    "                avg_train_acc,  # 現在の精度を出力\n",
    "                avg_val_loss,   # 現在の損失を出力\n",
    "                avg_val_acc     # 現在の精度を出力\n",
    "    ))\n",
    "\n",
    "# モデルの概要を出力\n",
    "model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ebeb28e6b13eca9129251e1a57a607330dbc2c0e4d49cedd0aa8c47b6d160812"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('image')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
