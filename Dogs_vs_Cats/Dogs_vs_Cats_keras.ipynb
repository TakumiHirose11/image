{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "_URL = \"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\"\n",
    "path_to_zip = tf.keras.utils.get_file(\"cat_and_dogs.zip\", origin=_URL, extract=True)\n",
    "PATH = os.path.join(os.path.dirname(path_to_zip), \"cats_and_dogs_filtered\")\n",
    "\n",
    "train_dir = os.path.join(PATH, \"train\")\n",
    "validation_dir = os.path.join(PATH, \"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define funtion generating data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def ImageDataGenerate(train_dir, validation_dir):\n",
    "\n",
    "    batch_size = 32\n",
    "    IMG_HEIGHT = 224\n",
    "    IMG_WIDTH = 224\n",
    "\n",
    "    \"\"\"data generator\"\"\"\n",
    "    train_image_generator = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=15,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"nearest\",\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "    )\n",
    "\n",
    "    validation_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    \"\"\"data\"\"\"\n",
    "    train_data_gen = train_image_generator.flow_from_directory(\n",
    "        batch_size=batch_size,\n",
    "        directory=train_dir,\n",
    "        shuffle=True,\n",
    "        target_size=(IMG_HEIGHT,IMG_WIDTH),\n",
    "        class_mode=\"binary\",\n",
    "    )\n",
    "\n",
    "    val_data_gen = validation_image_generator.flow_from_directory(\n",
    "        batch_size=batch_size,\n",
    "        directory=validation_dir,\n",
    "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        class_mode=\"binary\",\n",
    "    )\n",
    "\n",
    "    return train_data_gen, val_data_gen\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create function that make and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Dropout, MaxPooling2D, Flatten\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "def train_CNN(train_data_gen, val_data_gen):\n",
    "    \"\"\"\n",
    "    Returns: hisory\n",
    "    \"\"\"\n",
    "    image_size = len(train_data_gen[0][0][0])\n",
    "    input_shape = (image_size, image_size, 3)\n",
    "    batch_size = len(train_data_gen[0][0])\n",
    "    total_train = len(train_data_gen) * batch_size\n",
    "    total_validate = len(val_data_gen) * batch_size\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=(3,3),\n",
    "            input_shape=input_shape,\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        MaxPooling2D(pool_size=(2,2))\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        Dropout(0.25)\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=(3, 3),\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        MaxPooling2D(pool_size=(2,2))\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        Dropout(0.25)\n",
    "        )\n",
    "\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=(3,3),\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        MaxPooling2D(pool_size=(2,2))\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        Dropout(0.25)\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        Flatten()\n",
    "        )\n",
    "    \n",
    "    model.add(\n",
    "        Dense(\n",
    "            64,\n",
    "            activation=\"relu\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        Dropout(0.5)\n",
    "        )\n",
    "\n",
    "    model.add(\n",
    "        Dense(\n",
    "            1,\n",
    "            activation=\"sigmoid\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss = \"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "        optimizer=optimizers.Adam(),\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    epochs = 60\n",
    "    history = model.fit(\n",
    "        train_data_gen,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_data_gen,\n",
    "        validation_steps=total_validate // batch_size,\n",
    "        steps_per_epoch=total_train // batch_size,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning\n",
    "(出力reluにしてたらlossがずっと0.5だった笑)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_data_gen, val_data_gen = ImageDataGenerate(train_dir=train_dir, validation_dir=validation_dir)\n",
    "history = train_CNN(train_data_gen, val_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_acc_loss(history):\n",
    "    plt.plot(history.history[\"accuracy\"],\"-\",label=\"accuracy\")\n",
    "    plt.plot(history.history[\"val_accuracy\"],\"-\",label=\"val_acc\")\n",
    "    plt.title(\"accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history.history[\"loss\"],\"-\",label=\"loss\")\n",
    "    plt.plot(history.history[\"val_loss\"],\"-\",label=\"val_loss\")\n",
    "    plt.title(\"loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()\n",
    "\n",
    "plot_acc_loss(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.09733412 0.31553176 0.51271135]\n",
      "  [0.09803922 0.32122406 0.52837807]\n",
      "  [0.09413362 0.32952353 0.5412563 ]\n",
      "  ...\n",
      "  [0.6862745  0.454902   0.21960786]\n",
      "  [0.6862745  0.454902   0.21960786]\n",
      "  [0.6862745  0.454902   0.21960786]]\n",
      "\n",
      " [[0.09721021 0.31516004 0.511844  ]\n",
      "  [0.09803922 0.32110018 0.5280064 ]\n",
      "  [0.09422559 0.3291959  0.54085267]\n",
      "  ...\n",
      "  [0.6862745  0.454902   0.21960786]\n",
      "  [0.6862745  0.454902   0.21960786]\n",
      "  [0.6862745  0.454902   0.21960786]]\n",
      "\n",
      " [[0.0970863  0.31478834 0.5109767 ]\n",
      "  [0.09803922 0.3209763  0.5276347 ]\n",
      "  [0.0943495  0.3289481  0.5404809 ]\n",
      "  ...\n",
      "  [0.6862745  0.454902   0.21960786]\n",
      "  [0.6862745  0.454902   0.21960786]\n",
      "  [0.6862745  0.454902   0.21960786]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.47058827 0.3019608  0.16862746]\n",
      "  [0.47058827 0.3019608  0.16862746]\n",
      "  [0.47058827 0.3019608  0.16862746]\n",
      "  ...\n",
      "  [0.49803925 0.23529413 0.12156864]\n",
      "  [0.49803925 0.23529413 0.12156864]\n",
      "  [0.49803925 0.23529413 0.12156864]]\n",
      "\n",
      " [[0.47058827 0.3019608  0.16862746]\n",
      "  [0.47058827 0.3019608  0.16862746]\n",
      "  [0.47058827 0.3019608  0.16862746]\n",
      "  ...\n",
      "  [0.49803925 0.23529413 0.12156864]\n",
      "  [0.49803925 0.23529413 0.12156864]\n",
      "  [0.49803925 0.23529413 0.12156864]]\n",
      "\n",
      " [[0.47058827 0.3019608  0.16862746]\n",
      "  [0.47058827 0.3019608  0.16862746]\n",
      "  [0.47058827 0.3019608  0.16862746]\n",
      "  ...\n",
      "  [0.49803925 0.23529413 0.12156864]\n",
      "  [0.49803925 0.23529413 0.12156864]\n",
      "  [0.49803925 0.23529413 0.12156864]]]\n"
     ]
    }
   ],
   "source": [
    "print(train_data_gen[0][0][0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ebeb28e6b13eca9129251e1a57a607330dbc2c0e4d49cedd0aa8c47b6d160812"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('image')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
