{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning (VGG16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "_URL = \"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\"\n",
    "path_to_zip = tf.keras.utils.get_file(\"cat_and_dogs.zip\", origin=_URL, extract=True)\n",
    "PATH = os.path.join(os.path.dirname(path_to_zip), \"cats_and_dogs_filtered\")\n",
    "\n",
    "train_dir = os.path.join(PATH, \"train\")\n",
    "validation_dir = os.path.join(PATH, \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def ImageDataGenerate(train_dir, validation_dir):\n",
    "\n",
    "    batch_size = 32\n",
    "    IMG_HEIGHT = 224\n",
    "    IMG_WIDTH = 224\n",
    "\n",
    "    \"\"\"data generator\"\"\"\n",
    "    train_image_generator = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=15,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"nearest\",\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "    )\n",
    "\n",
    "    validation_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    \"\"\"data\"\"\"\n",
    "    train_data_gen = train_image_generator.flow_from_directory(\n",
    "        batch_size=batch_size,\n",
    "        directory=train_dir,\n",
    "        shuffle=True,\n",
    "        target_size=(IMG_HEIGHT,IMG_WIDTH),\n",
    "        class_mode=\"binary\",\n",
    "    )\n",
    "\n",
    "    val_data_gen = validation_image_generator.flow_from_directory(\n",
    "        batch_size=batch_size,\n",
    "        directory=validation_dir,\n",
    "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        class_mode=\"binary\",\n",
    "    )\n",
    "\n",
    "    return train_data_gen, val_data_gen\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalMaxPooling2D\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "\n",
    "def train_FClayer(train_data_gen, val_data_gen):\n",
    "    image_size = len(train_data_gen[0][0][0])\n",
    "    input_shape = (image_size, image_size, 3)\n",
    "    batch_size = len(train_data_gen[0][0])\n",
    "    total_train = len(train_data_gen) * batch_size\n",
    "    total_validate = len(val_data_gen) * batch_size\n",
    "\n",
    "    pre_trained_model = VGG16(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=input_shape,\n",
    "    )\n",
    "\n",
    "    for layer in pre_trained_model.layers[:15]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    for layer in pre_trained_model.layers[15:]:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(pre_trained_model)\n",
    "\n",
    "    model.add(\n",
    "        GlobalMaxPooling2D()\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        Dropout(0.5)\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        Dense(\n",
    "            512,\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(\n",
    "        Dense(\n",
    "            1,\n",
    "            activation=\"sigmoid\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=optimizers.RMSprop(learning_rate=1e-5),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    def step_decay(epoch):\n",
    "        initial_lrate = 0.00001\n",
    "        drop = 0.5\n",
    "        epochs_drop = 10.0\n",
    "        lrate = initial_lrate * math.pow(\n",
    "            drop,\n",
    "            math.floor((epoch)/epochs_drop),\n",
    "        )\n",
    "        return lrate\n",
    "    \n",
    "    lrate = LearningRateScheduler(step_decay)\n",
    "\n",
    "    epochs = 40\n",
    "    history = model.fit(\n",
    "        train_data_gen,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_data_gen,\n",
    "        validation_steps=total_validate // batch_size,\n",
    "        steps_per_epoch=total_train // batch_size,\n",
    "        verbose=1,\n",
    "        callbacks=[lrate],\n",
    "    )\n",
    "\n",
    "    return history\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 14,977,857\n",
      "Trainable params: 7,342,593\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x2945308b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x2945308b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m/Users/hirosetakumi/development/image/Dogs_vs_Cats/fine-tuning.ipynb Cell 5'\u001b[0m in \u001b[0;36mtrain_FClayer\u001b[0;34m(train_data_gen, val_data_gen)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hirosetakumi/development/image/Dogs_vs_Cats/fine-tuning.ipynb#ch0000002?line=72'>73</a>\u001b[0m lrate \u001b[39m=\u001b[39m LearningRateScheduler(step_decay)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hirosetakumi/development/image/Dogs_vs_Cats/fine-tuning.ipynb#ch0000002?line=74'>75</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m40\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hirosetakumi/development/image/Dogs_vs_Cats/fine-tuning.ipynb#ch0000002?line=75'>76</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hirosetakumi/development/image/Dogs_vs_Cats/fine-tuning.ipynb#ch0000002?line=76'>77</a>\u001b[0m     train_data_gen,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hirosetakumi/development/image/Dogs_vs_Cats/fine-tuning.ipynb#ch0000002?line=77'>78</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hirosetakumi/development/image/Dogs_vs_Cats/fine-tuning.ipynb#ch0000002?line=78'>79</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mval_data_gen,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hirosetakumi/development/image/Dogs_vs_Cats/fine-tuning.ipynb#ch0000002?line=79'>80</a>\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mtotal_validate \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m batch_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hirosetakumi/development/image/Dogs_vs_Cats/fine-tuning.ipynb#ch0000002?line=80'>81</a>\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49mtotal_train \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m batch_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hirosetakumi/development/image/Dogs_vs_Cats/fine-tuning.ipynb#ch0000002?line=81'>82</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hirosetakumi/development/image/Dogs_vs_Cats/fine-tuning.ipynb#ch0000002?line=82'>83</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[lrate],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hirosetakumi/development/image/Dogs_vs_Cats/fine-tuning.ipynb#ch0000002?line=83'>84</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hirosetakumi/development/image/Dogs_vs_Cats/fine-tuning.ipynb#ch0000002?line=85'>86</a>\u001b[0m \u001b[39mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1092'>1093</a>\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1093'>1094</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1094'>1095</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1095'>1096</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1096'>1097</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1097'>1098</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1098'>1099</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1099'>1100</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1100'>1101</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1101'>1102</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=825'>826</a>\u001b[0m tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=826'>827</a>\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name) \u001b[39mas\u001b[39;00m tm:\n\u001b[0;32m--> <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=827'>828</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=828'>829</a>\u001b[0m   compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experimental_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=829'>830</a>\u001b[0m   new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m~/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:888\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=883'>884</a>\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=884'>885</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=885'>886</a>\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=886'>887</a>\u001b[0m     \u001b[39m# stateless function.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=887'>888</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=888'>889</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=889'>890</a>\u001b[0m   _, _, _, filtered_flat_args \u001b[39m=\u001b[39m \\\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=890'>891</a>\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mcanonicalize_function_inputs(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=891'>892</a>\u001b[0m           \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2942\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=2938'>2939</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=2939'>2940</a>\u001b[0m   (graph_function,\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=2940'>2941</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=2941'>2942</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=2942'>2943</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1913'>1914</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1914'>1915</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1915'>1916</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1916'>1917</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1917'>1918</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1918'>1919</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1919'>1920</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1920'>1921</a>\u001b[0m     args,\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1921'>1922</a>\u001b[0m     possible_gradient_type,\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1922'>1923</a>\u001b[0m     executing_eagerly)\n\u001b[1;32m   <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1923'>1924</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py:555\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=552'>553</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=553'>554</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=554'>555</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=555'>556</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=556'>557</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=557'>558</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=558'>559</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=559'>560</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=560'>561</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=561'>562</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=562'>563</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=563'>564</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=566'>567</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=567'>568</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=57'>58</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=58'>59</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=59'>60</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=60'>61</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='file:///Users/hirosetakumi/miniforge3/envs/image/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=61'>62</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_data_gen, val_data_gen = ImageDataGenerate(train_dir, validation_dir)\n",
    "history = train_FClayer(train_data_gen, val_data_gen)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ebeb28e6b13eca9129251e1a57a607330dbc2c0e4d49cedd0aa8c47b6d160812"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('image')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
