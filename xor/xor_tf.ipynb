{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "XOR gate by Tensorflow\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "train = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "label = np.array([[0],[1],[1],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class MLP(tf.keras.Model): #MultiLayerPerceptron\n",
    "    \"\"\"\n",
    "    l1(Dense);隠れ層\n",
    "    l2(Dense):出力層\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.l1 = tf.keras.layers.Dense(\n",
    "            units=hidden_dim,\n",
    "            input_dim=input_dim,\n",
    "            activation=\"sigmoid\",\n",
    "        )\n",
    "        self.l2 = tf.keras.layers.Dense(\n",
    "            units = output_dim,\n",
    "            activation=\"sigmoid\",\n",
    "        )\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, x, training = None):\n",
    "        \"\"\"\n",
    "        Function of callback from instance of model\n",
    "\n",
    "        ”forward propagation processing（順伝播による処理）”\n",
    "\n",
    "        x(ndarray(float32)): train data\n",
    "        training(bool): train True, varidation False\n",
    "        Return : output\n",
    "        \"\"\"\n",
    "        h = self.l1(x)\n",
    "        y = self.l2(h)\n",
    "        return y\n",
    "\n",
    "model = MLP(2,2,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Update Parameter\n",
    "\"\"\"\n",
    "@tf.function\n",
    "def train_step(x, t):\n",
    "    \"\"\"\n",
    "    x: train data\n",
    "    t: label\n",
    "    return: pred_loss\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x)\n",
    "        pred_loss = loss_fn(t, predictions)\n",
    "    \n",
    "    gradients = tape.gradient(\n",
    "        pred_loss,\n",
    "        model.trainable_variables,\n",
    "    )\n",
    "    \n",
    "    optimizer.apply_gradients(\n",
    "        zip(gradients, model.trainable_variables)\n",
    "    )\n",
    "    return pred_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-06 12:43:09.672665: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-06-06 12:43:09.673751: W tensorflow/core/platform/profile_utils/cpu_utils.cc:126] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(1000) loss:  0.399343\n",
      "epoch(2000) loss:  0.358488\n",
      "epoch(3000) loss:  0.352922\n",
      "epoch(4000) loss:  0.350858\n",
      "Model: \"mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  6         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  3         \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Learning\n",
    "\"\"\"\n",
    "epochs = 4000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.\n",
    "\n",
    "    loss = train_step(train, label)\n",
    "    epoch_loss += loss.numpy()\n",
    "\n",
    "    if (epoch + 1)%1000 ==0:\n",
    "        print(\"epoch({}) loss: {: 4f}\".format(epoch+1, epoch_loss))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.00538131]\n",
      " [0.9949844 ]\n",
      " [0.4991716 ]\n",
      " [0.5025197 ]], shape=(4, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " [1]], shape=(4, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Evaluate model\n",
    "\"\"\"\n",
    "print(model(train))\n",
    "print(tf.cast(((model(train)) >= 0.5) , tf.int32))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ebeb28e6b13eca9129251e1a57a607330dbc2c0e4d49cedd0aa8c47b6d160812"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('image')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
